import torch
import torch.nn as nn
import torch.nn.functional as F

from encoding import get_encoder
from activation import trunc_exp
from .renderer import NeRFRenderer

import pdb
from lib.precision import *
import math

import csv
import numpy as np

class NeRFNetwork(NeRFRenderer):
    def __init__(self,
                 encoding="hashgrid",
                 encoding_dir="sphere_harmonics",
                 encoding_bg="hashgrid",
                 num_layers=2,
                 hidden_dim=64,
                 geo_feat_dim=15,
                 num_layers_color=3,
                 hidden_dim_color=64,
                 num_layers_bg=2,
                 hidden_dim_bg=64,
                 bound=1,
                 fxp=False,
                 fxp_bw=8,
                 **kwargs,
                 ):
        super().__init__(bound, **kwargs)

        self.fxp = fxp
        self.fxp_bw = fxp_bw
        self.encoding = encoding

        # sigma network
        self.num_layers = num_layers
        self.hidden_dim = hidden_dim
        self.geo_feat_dim = geo_feat_dim
        self.encoder, self.in_dim = get_encoder(encoding, desired_resolution=2048 * bound)
        

        sigma_net = []
        sigma_pruned_net = []
        for l in range(num_layers):
            if l == 0:
                in_dim = self.in_dim
            else:
                in_dim = hidden_dim
            
            if l == num_layers - 1:
                out_dim = 1 + self.geo_feat_dim # 1 sigma + 15 SH features for color
            else:
                out_dim = hidden_dim
            
            sigma_net.append(nn.Linear(in_dim, out_dim, bias=False))
            sigma_pruned_net.append(nn.Linear(in_dim, out_dim, bias=False))
        

        self.sigma_net = nn.ModuleList(sigma_net)
        self.sigma_pruned_net = nn.ModuleList(sigma_pruned_net)

        self.sigma_net_prun_ratio = 1


        # color network
        self.num_layers_color = num_layers_color        
        self.hidden_dim_color = hidden_dim_color
        self.encoder_dir, self.in_dim_dir = get_encoder(encoding_dir)
        
        color_net =  []
        for l in range(num_layers_color):
            if l == 0:
                in_dim = self.in_dim_dir + self.geo_feat_dim
            else:
                in_dim = hidden_dim
            
            if l == num_layers_color - 1:
                out_dim = 3 # 3 rgb
            else:
                out_dim = hidden_dim
            
            color_net.append(nn.Linear(in_dim, out_dim, bias=False))

        self.color_net = nn.ModuleList(color_net)

        # background network
        if self.bg_radius > 0:
            self.num_layers_bg = num_layers_bg        
            self.hidden_dim_bg = hidden_dim_bg
            self.encoder_bg, self.in_dim_bg = get_encoder(encoding_bg, input_dim=2, num_levels=4, log2_hashmap_size=19, desired_resolution=2048) # much smaller hashgrid 
            
            bg_net = []
            for l in range(num_layers_bg):
                if l == 0:
                    in_dim = self.in_dim_bg + self.in_dim_dir
                else:
                    in_dim = hidden_dim_bg
                
                if l == num_layers_bg - 1:
                    out_dim = 3 # 3 rgb
                else:
                    out_dim = hidden_dim_bg
                
                bg_net.append(nn.Linear(in_dim, out_dim, bias=False))

            self.bg_net = nn.ModuleList(bg_net)
        else:
            self.bg_net = None


    def forward(self, x, d):
        # x: [N, 3], in [-bound, bound]
        # d: [N, 3], nomalized in [-1, 1]

        # sigma
        x = self.encoder(x, bound=self.bound)

        h = x
        pdb.set_trace()
        for l in range(self.num_layers):
            #### SR Quantization ####
            if self.fxp and l>0 and l<self.num_layers-1:
                if h.max()<=1 :
                    i_int_bw = 0
                else:
                    i_int_bw = math.log2(h.max())
                h = custom_precision(h, i_int_bw, self.fxp_bw-1-i_int_bw, 'fxp')
                
            h = self.sigma_net[l](h)
            if l != self.num_layers - 1:
                h = F.relu(h, inplace=True)

        pdb.set_trace()
        #sigma = F.relu(h[..., 0])
        sigma = trunc_exp(h[..., 0])
        geo_feat = h[..., 1:]

        # color
        
        d = self.encoder_dir(d)
        h = torch.cat([d, geo_feat], dim=-1)
        for l in range(self.num_layers_color):
            h = self.color_net[l](h)
            if l != self.num_layers_color - 1:
                h = F.relu(h, inplace=True)
        
        # sigmoid activation for rgb
        color = torch.sigmoid(h)

        return sigma, color

    def density(self, x):
        # x: [N, 3], in [-bound, bound]
        print(self.sigma_net)
        print("nerwork.py (151) density func")
        if self.encoding == 'frequency':
            x = self.encoder(x)
        elif self.encoding == 'hashgrid':
            x = self.encoder(x, bound=self.bound)


        h = x
        h_prun = x
        for l in range(self.num_layers):
            inputfile_name = "./intermediate/sigmaNet_layer" + str(l) + "_origin_input.csv"
            outputfile_name = "./intermediate/sigmaNet_layer" + str(l) + "_origin_output.csv"
            prun_inputfile_name = "./intermediate/sigmaNet_layer" + str(l) + "_prun_input.csv"
            prun_outputfile_name = "./intermediate/sigmaNet_layer" + str(l) + "_prun_output.csv"

            #### SR Quantization ####
            if self.fxp and l>0 and l<self.num_layers-1:
                i_int_bw = int(math.log2(h.max()))
                h = custom_precision(h, i_int_bw, self.fxp_bw-1-i_int_bw, 'fxp')
            if self.fxp and l>0 and l<self.num_layers-1:
                i_int_bw = int(math.log2(h_prun.max()))
                h_prun = custom_precision(h_prun, i_int_bw, self.fxp_bw-1-i_int_bw, 'fxp')

            #### SR input data log ####
            with open (inputfile_name, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerows(h.cpu().numpy())
                torch.save(h,"./intermediate/sigmaNet_layer" + str(l) + "_origin_input.pth")
            with open (prun_inputfile_name, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerows(h_prun.cpu().numpy())
                torch.save(h_prun,"./intermediate/sigmaNet_layer" + str(l) + "_prun_input.pth")
            
            #### Inference & Activation Func ####
            h = self.sigma_net[l](h)
            h_prun = self.sigma_pruned_net[l](h_prun)
            if l != self.num_layers - 1:
                h = F.relu(h, inplace=True)
                h_prun = F.relu(h_prun, inplace=True)

            #### SR batch directional weight pruning ####
            if l != self.num_layers - 1:
                pdb.set_trace()
                h_mean = h.mean(0)
                h_mean = np.mean(h.detach().cpu().numpy(), axis = 0) 
                print(str(l)+"th layer mean value: ",h_mean)

                h_max_of_mean = np.max(h_mean)
                print(str(l)+"th layer max of mean value: ",h_max_of_mean)
                h_pruning_th = h_max_of_mean*self.sigma_net_prun_ratio
                print(str(l)+"th layer pruning threshold: ",h_pruning_th)


                h_important_ich = h_mean > h_pruning_th
                print(str(l)+"th layer important ich value: ",h_important_ich)

                w_mask = h_important_ich

                w_nxt_layer = self.sigma_pruned_net[l+1].weight.cpu().numpy()
                origin_w_nxt_layer = self.sigma_net[l+1].weight.cpu().numpy() 
                print(str(l+1)+" nxt w:", w_nxt_layer)
                w_pruned_nxt_layer = w_nxt_layer * w_mask
                print(str(l+1)+" nxt pruned w:", w_pruned_nxt_layer)
                print(str(l+1)+" original nxt pruned w:", origin_w_nxt_layer)
                #self.sigma_pruned_net[l+1].weight = torch.Tensor(w_pruned_nxt_layer)
                self.sigma_pruned_net[l+1].weight.data = torch.Tensor(w_pruned_nxt_layer)


            #### SR output data log #### 
            with open (outputfile_name, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerows(h.cpu().numpy())
                torch.save(h,"./intermediate/sigmaNet_layer" + str(l) + "_origin_output.pth")

            with open (prun_outputfile_name, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerows(h_prun.cpu().numpy())
                torch.save(h_prun,"./intermediate/sigmaNet_layer" + str(l) + "_prun_output.pth")               

        #sigma = F.relu(h[..., 0])

        sigmafile_name = "./intermediate/sigmaNet_layer" + str(l) + "_origin_sigma.csv"
        prun_sigmafile_name = "./intermediate/sigmaNet_layer" + str(l) + "_prun_sigma.csv"
        print(h.shape)
        sigma = trunc_exp(h[..., 0])
        sigma_prun = trunc_exp(h_prun[..., 0])

        #### SR sigma data log #### 
        with open (sigmafile_name, 'w', newline='') as f:
            writer = csv.writer(f)
            for item in sigma:
                writer.writerow(sigma.cpu().numpy())
                torch.save(h,"./intermediate/sigmaNet_layer_origin_sigma.pth")

        with open (prun_sigmafile_name, 'w', newline='') as f:
            writer = csv.writer(f)
            for item in sigma:
                writer.writerow(sigma_prun.cpu().numpy())
                torch.save(h,"./intermediate/sigmaNet_layer_prun_sigma.pth")

        print(sigma.shape)
        print(sigma)

        #### SR pruned weight & original weight log ####
        for l in range(self.num_layers):
            origin_wfile_name = "./weight/sigmaNet_layer" + str(l) + "_origin_weight.csv"
            pruned_wfile_name = "./weight/sigmaNet_layer" + str(l) + "_pruned_weight.csv"

            with open (origin_wfile_name, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerows(np.abs(self.sigma_net[l].weight.data.cpu().numpy()))
                torch.save(self.sigma_net[l].weight.data,"./weight/sigmaNet_layer" + str(l) + "_origin_weight.pth")

            with open (pruned_wfile_name, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerows(np.abs(self.sigma_pruned_net[l].weight.data.cpu().numpy()))
                torch.save(self.sigma_pruned_net[l].weight.data,"./weight/sigmaNet_layer" + str(l) + "_pruned_weight.pth")

        geo_feat = h[..., 1:]

        return {
            'sigma': sigma,
            'geo_feat': geo_feat,
            'sigma_prun': sigma_prun
        }

    def background(self, x, d):
        # x: [N, 2], in [-1, 1]

        h = self.encoder_bg(x) # [N, C]
        d = self.encoder_dir(d)

        h = torch.cat([d, h], dim=-1)
        for l in range(self.num_layers_bg):
            h = self.bg_net[l](h)
            if l != self.num_layers_bg - 1:
                h = F.relu(h, inplace=True)
        
        # sigmoid activation for rgb
        rgbs = torch.sigmoid(h)

        return rgbs

    # allow masked inference
    def color(self, x, d, mask=None, geo_feat=None, **kwargs):
        # x: [N, 3] in [-bound, bound]
        # mask: [N,], bool, indicates where we actually needs to compute rgb.

        if mask is not None:
            rgbs = torch.zeros(mask.shape[0], 3, dtype=x.dtype, device=x.device) # [N, 3]
            # in case of empty mask
            if not mask.any():
                return rgbs
            x = x[mask]
            d = d[mask]
            geo_feat = geo_feat[mask]

        d = self.encoder_dir(d)
        h = torch.cat([d, geo_feat], dim=-1)
        for l in range(self.num_layers_color):
            h = self.color_net[l](h)
            if l != self.num_layers_color - 1:
                h = F.relu(h, inplace=True)
        
        # sigmoid activation for rgb
        h = torch.sigmoid(h)

        if mask is not None:
            rgbs[mask] = h.to(rgbs.dtype) # fp16 --> fp32
        else:
            rgbs = h

        return rgbs        

    # optimizer utils
    def get_params(self, lr):

        params = [
            {'params': self.encoder.parameters(), 'lr': lr},
            {'params': self.sigma_net.parameters(), 'lr': lr},
            {'params': self.encoder_dir.parameters(), 'lr': lr},
            {'params': self.color_net.parameters(), 'lr': lr}, 
        ]
        if self.bg_radius > 0:
            params.append({'params': self.encoder_bg.parameters(), 'lr': lr})
            params.append({'params': self.bg_net.parameters(), 'lr': lr})
        
        return params
